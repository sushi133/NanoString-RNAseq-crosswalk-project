{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c215f8-f111-4684-bf3d-23763f0ca7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from xgboost import XGBRegressor  # Import Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e73aa-e9e5-47be-bc05-727db7ec020f",
   "metadata": {},
   "source": [
    "## Prep the Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65eadf1-49d2-44d2-b851-603381e8a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "print(\"STARTING\")\n",
    "# Get the number of patients and genes\n",
    "n_patients = 100  # Number of patients\n",
    "n_genes = 800    # Number of genes\n",
    "\n",
    "# Define correlation structure between pre-treatment and post-treatment\n",
    "correlation = 0.7  # High correlation between pre-treatment and post-treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a36eb2-e5fd-498b-b345-4ed458d58c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random counts for Platform 1 (pre-treatment) from Poisson distribution\n",
    "platform1_pre = np.random.poisson(lam=10, size=(n_patients, n_genes))\n",
    "\n",
    "# Generate random counts for Platform 2 (pre-treatment) with linear transformation + noise\n",
    "true_coefficients = np.random.normal(0, 0.5, n_genes)  # True relationship\n",
    "noise = np.random.normal(0, 1, size=(n_patients, n_genes))\n",
    "platform2_pre = np.dot(platform1_pre, np.diag(true_coefficients)) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc70ecc-bc6a-4595-b0db-8235e970c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip negative values for realistic counts\n",
    "platform2_pre = np.clip(platform2_pre, 0, None)\n",
    "\n",
    "# Generate correlated pre-treatment and post-treatment data for each gene\n",
    "pre_treatment = np.column_stack([platform1_pre, platform2_pre])\n",
    "\n",
    "# Initialize matrix for post-treatment data\n",
    "post_treatment = np.zeros_like(pre_treatment)\n",
    "\n",
    "# Create correlation matrix for each gene\n",
    "for i in range(n_genes):\n",
    "    # Generate correlated post-treatment data based on pre-treatment\n",
    "    post_treatment[:, i] = pre_treatment[:, i] * (1 + np.random.normal(0, correlation, n_patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c04120a-ac18-440a-a74b-3c27015e3ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.29732155, 15.63642087, 27.44390717, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(post_treatment.shape) # rows = patients & \n",
    "post_treatment[1:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c4540b-bd56-4ae1-98b2-a92236913186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split pre-treatment and post-treatment data\n",
    "platform1_post = post_treatment[:, :n_genes]  # First half for platform1 post-treatment\n",
    "platform2_post = post_treatment[:, n_genes:]  # Second half for platform2 post-treatment\n",
    "\n",
    "# Clip negative values for post-treatment counts\n",
    "platform1_post = np.clip(platform1_post, 0, None)\n",
    "platform2_post = np.clip(platform2_post, 0, None)\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_platform1_pre = pd.DataFrame(platform1_pre, columns=[f\"gene_{i+1}\" for i in range(n_genes)])\n",
    "df_platform2_pre = pd.DataFrame(platform2_pre, columns=[f\"gene_{i+1}\" for i in range(n_genes)])\n",
    "df_platform1_post = pd.DataFrame(platform1_post, columns=[f\"gene_{i+1}\" for i in range(n_genes)])\n",
    "df_platform2_post = pd.DataFrame(platform2_post, columns=[f\"gene_{i+1}\" for i in range(n_genes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80344108-0792-4ea4-b276-7c1bc7e4a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pre-treatment and post-treatment data into one DataFrame\n",
    "df_platform1 = pd.concat([df_platform1_pre, df_platform1_post], axis=1, keys=[\"pre_treatment\", \"post_treatment\"])\n",
    "df_platform2 = pd.concat([df_platform2_pre, df_platform2_post], axis=1, keys=[\"pre_treatment\", \"post_treatment\"])\n",
    "\n",
    "# Combine both pre- and post-treatment data for training and testing\n",
    "X = pd.concat([df_platform1[\"pre_treatment\"], df_platform1[\"post_treatment\"]], axis=1)\n",
    "y = pd.concat([df_platform2[\"pre_treatment\"], df_platform2[\"post_treatment\"]], axis=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7bf850-a2ef-4f3c-8227-faf5e5c4983c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1600)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fbcb614-3eeb-4126-a6da-2ab827715eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987b3c72-9492-4805-a511-ece0460d877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hopekirby/miniconda3/envs/sclinker/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# --- Lasso Regression ---\n",
    "lasso = Lasso(alpha=0.1)  # Adjust alpha for stronger/weaker regularization\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test_scaled)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7903705a-cff9-4211-b517-7a1045f7f245",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Gradient Boosting (XGBoost) ---\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mXGBRegressor\u001b[49m(\n\u001b[1;32m      3\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,    \u001b[38;5;66;03m# Number of trees\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,         \u001b[38;5;66;03m# Maximum depth of a tree\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,   \u001b[38;5;66;03m# Step size shrinkage\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m      \u001b[38;5;66;03m# For reproducibility\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      9\u001b[0m y_pred_xgb \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XGBRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Gradient Boosting (XGBoost) ---\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=100,    # Number of trees\n",
    "    max_depth=6,         # Maximum depth of a tree\n",
    "    learning_rate=0.1,   # Step size shrinkage\n",
    "    random_state=random_seed      # For reproducibility\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5696cd-a68a-4cfd-94bb-4bd3a3f29e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38547c54-5286-49c7-94cf-252dd18c6bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb78c159-87d5-428b-97f0-e14d72cc0946",
   "metadata": {},
   "source": [
    "## Predict regardless of Pre vs Post?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c39ec-2dfc-40c6-a5be-0e27ab16c53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sclinker",
   "language": "python",
   "name": "sclinker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
